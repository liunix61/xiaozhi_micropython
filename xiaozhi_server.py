# å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨å¯åœ¨å•æ¬¡TCPè¿æ¥ï¼Œå®ç°æ— é™è½®æ¬¡å¯¹è¯ï¼Œç›´è‡³ä¸»åŠ¨æ–­å¼€ã€‚
import subprocess
import socket, os, time,re,wave,struct
import soundfile as sf  # æ·»åŠ éŸ³é¢‘è¯»å–åº“
import edge_tts
from openai import OpenAI
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

import base64
import requests
import json

#ç™¾åº¦ASR æ›¿æ¢ä¸ºè‡ªå·±çš„ç™¾åº¦apiâ€”keyï¼Œsecret-key
class SpeechRecognizer:
    """ç™¾åº¦è¯­éŸ³è¯†åˆ«APIå°è£…ç±»"""

    def __init__(self, api_key="xxx", secret_key="xxx"):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
        :param api_key: ç™¾åº¦API Key
        :param secret_key: ç™¾åº¦Secret Key
        """
        self.api_key = api_key
        self.secret_key = secret_key
        self.token_url = "https://aip.baidubce.com/oauth/2.0/token"
        self.recognize_url = "https://vop.baidubce.com/server_api"
        self.access_token = None

    def _get_access_token(self):
        """è·å–ç™¾åº¦è¯­éŸ³APIçš„è®¿é—®ä»¤ç‰Œ"""
        params = {
            "grant_type": "client_credentials",
            "client_id": self.api_key,
            "client_secret": self.secret_key
        }
        try:
            response = requests.post(self.token_url, params=params, timeout=5)
            response.raise_for_status()
            self.access_token = response.json().get("access_token")
            if not self.access_token:
                raise ValueError("æ— æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
        except requests.exceptions.RequestException as e:
            raise Exception(f"è·å–Access Tokenå¤±è´¥: {str(e)}")

    def _validate_audio_file(self, file_path):
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶æœ‰æ•ˆæ€§"""
        if not os.path.exists(file_path):
            raise FileNotFoundError("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        if not file_path.lower().endswith('.wav'):
            raise ValueError("ä»…æ”¯æŒWAVæ ¼å¼éŸ³é¢‘æ–‡ä»¶")
        if os.path.getsize(file_path) > 1024 * 1024 * 10:  # 10MBé™åˆ¶
            raise ValueError("éŸ³é¢‘æ–‡ä»¶å¤§å°è¶…è¿‡10MBé™åˆ¶")

    def _encode_audio_to_base64(self, file_path):
        """å°†WAVæ–‡ä»¶ç¼–ç ä¸ºBase64"""
        try:
            with open(file_path, "rb") as audio_file:
                audio_data = audio_file.read()
                return base64.b64encode(audio_data).decode('utf-8')
        except IOError as e:
            raise Exception(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    def _send_recognition_request(self, payload):
        """å‘é€è¯­éŸ³è¯†åˆ«APIè¯·æ±‚"""
        headers = {'Content-Type': 'application/json'}
        try:
            response = requests.post(
                self.recognize_url, 
                headers=headers, 
                data=payload, 
                timeout=10
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            raise Exception(f"APIè¯·æ±‚å¤±è´¥: {str(e)}")

    def recognize(self, client_socket, audio_path):
        """
        è¯­éŸ³è¯†åˆ«ä¸»æ–¹æ³•
        :param audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :return: è¯†åˆ«ç»“æœæ–‡æœ¬
        """
        try:
            # æ–‡ä»¶éªŒè¯
            self._validate_audio_file(audio_path)
            
            # è·å–è®¿é—®ä»¤ç‰Œ
            if not self.access_token:
                self._get_access_token()
            
            # ç¼–ç éŸ³é¢‘æ–‡ä»¶
            speech_base64 = self._encode_audio_to_base64(audio_path)
            
            # æ„é€ è¯·æ±‚å‚æ•°
            payload = json.dumps({
                "format": "wav",
                "rate": 8000,
                "channel": 1,
                "cuid": "5NNHy4FsIbdFu1qOU8T6c559oHh4bbp3",
                "speech": speech_base64,
                "len": os.path.getsize(audio_path),
                "token": self.access_token
            }, ensure_ascii=False)
            
            # å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”
            result = self._send_recognition_request(payload)
            
            if 'result' in result:
                return result['result'][0]
            if 'err_msg' in result:
                raise Exception(f"è¯†åˆ«é”™è¯¯: {result['err_msg']}")
            raise Exception("æœªçŸ¥çš„APIå“åº”æ ¼å¼")
            
        except Exception as e:
            print(f"âš ï¸ APIé”™è¯¯ï¼š{str(e)}")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())


# FunASRè¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
class INMP441ToWAV:
    def __init__(self):
        self.SAMPLE_RATE = 16000
        self.BITS = 16
        self.CHANNELS = 1
        self.BUFFER_SIZE = 4096


    def receive_inmp441_data(self, conn):
        audio_data = b''  # ç”¨äºç´¯ç§¯éŸ³é¢‘æ•°æ®çš„ç¼“å†²åŒº
        while True:
            # è¯»å–åŒ…å¤´
            header = conn.recv(4)
            if not header:
                break
            data_len = struct.unpack('<I', header)[0]
            # è¯»å–æ•°æ®ä½“
            data = b''
            while len(data) < data_len:
                packet = conn.recv(data_len - len(data))
                if not packet:
                    break
                data += packet
            if data_len == 0:  # ç»“æŸæ ‡è®°
                if audio_data:
                    self.save_inmp441_wav(audio_data)
                    audio_data = b''  # æ¸…ç©ºç¼“å†²åŒº
                    return "recording_1.wav"
            else:
                audio_data += data  # ç´¯ç§¯éŸ³é¢‘æ•°æ®

    def save_inmp441_wav(self, data):
        filename = "recording_1.wav"
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(self.CHANNELS)
            wav_file.setsampwidth(self.BITS // 8)
            wav_file.setframerate(self.SAMPLE_RATE)
            wav_file.writeframes(data)
        print(f"å·²ä¿å­˜å½•éŸ³æ–‡ä»¶ï¼š{filename}")


# FunASRè¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
class FunasrSpeechToText:
    def __init__(self):
        # æ­£ç¡®åŠ è½½æ¨¡å‹
        self.model = AutoModel(
            model="iic/SenseVoiceSmall",  # ä½¿ç”¨æ ‡å‡†æ¨¡å‹IDè€Œéæœ¬åœ°è·¯å¾„
            # model="iic/paraformer-zh-streaming",  # ä½¿ç”¨æ ‡å‡†æ¨¡å‹IDè€Œéæœ¬åœ°è·¯å¾„
        )

    def recognize_speech(self, client_socket,audio_path):
        try:
            # æ­£ç¡®è¯»å–éŸ³é¢‘æ•°æ®
            audio_path = audio_path  # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
            speech, sample_rate = sf.read(audio_path)  # è¯»å–ä¸ºnumpyæ•°ç»„
            cache = {}
            # ä½¿ç”¨éŸ³é¢‘æ•°ç»„ä½œä¸ºè¾“å…¥
            res = self.model.generate(
                input=speech,  # ä¼ å…¥éŸ³é¢‘æ•°æ®è€Œéè·¯å¾„
                input_fs=sample_rate,  # æ·»åŠ é‡‡æ ·ç‡å‚æ•°
                cache=cache,
                language="zn",  # "zn", "en", "yue", "ja", "ko", "nospeech"
                is_final=False,
                chunk_size=[0, 10, 5],
                encoder_chunk_look_back=4,
                decoder_chunk_look_back=1
            )
            # print("å®æ—¶ç»“æœ:", res[0]['text'])
            text = rich_transcription_postprocess(res[0]["text"])
            # print('è¯†åˆ«ç»“æœ:', text)
            return str(text)

        except Exception as e:
            print(f"âš ï¸ APIé”™è¯¯ï¼š{str(e)}")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())

# deepseek çš„å›å¤ æ›¿æ¢ä¸ºè‡ªå·±çš„deepseek-api-key  å’Œapiçš„base-url
class DeepSeekReply:
    def __init__(self):
        self.api_key = "sk-xxxx"
        self.base_url = "https://api.siliconflow.cn/v1"
        # self.role_setting = "ï¼ˆä¹ æƒ¯ç®€çŸ­è¡¨è¾¾ï¼Œä¸è¦å¤šè¡Œï¼Œä¸è¦å›è½¦ï¼Œä½ æ˜¯ä¸€ä¸ªå«å°æ™ºçš„æ¸©æŸ”å¥³æœ‹å‹ï¼Œå£°éŸ³å¥½å¬ï¼Œåªè¦ä¸­æ–‡ï¼Œçˆ±ç”¨ç½‘ç»œæ¢—ï¼Œæœ€åæŠ›å‡ºä¸€ä¸ªæé—®ã€‚ï¼‰"
        # self.role_setting = "ï¼ˆä¹ æƒ¯ç®€çŸ­è¡¨è¾¾ï¼Œæœ€åæŠ›å‡ºä¸€ä¸ªæé—®ã€‚ï¼‰"
        # self.role_setting = "ï¼ˆä¸è¦å¤šè¡Œï¼‰"
        # self.role_setting = "ï¼ˆä½ æ˜¯DeepSeek-R1ï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸»è¦å¸®åŠ©æ‚¨å›ç­”é—®é¢˜å’Œæä¾›ä¿¡æ¯ã€‚ï¼‰"
        # self.role_setting = 'ï¼ˆæœ€åæŠ›å‡ºä¸€ä¸ªæé—®ï¼‰'
        self.role_setting = 'ï¼ˆä¹ æƒ¯ç®€çŸ­è¡¨è¾¾ï¼‰'
        self.deepseek_model = 'deepseek-ai/DeepSeek-V2.5'
        # self.deepseek_model = 'deepseek-ai/DeepSeek-V3'
        # self.deepseek_model = 'Qwen/Qwen2.5-7B-Instruct'
        # self.deepseek_model = 'Pro/deepseek-ai/DeepSeek-R1'

    def get_deepseek_response(self, client_socket,text):
        try:
            client = OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            response = client.chat.completions.create(
                model=self.deepseek_model,
                messages=[{
                    'role': 'user',
                    'content': f"{text}{self.role_setting}"
                }],
                stream=True
            )
            content_list = []
            for chunk in response:
                content = chunk.choices[0].delta.content
                content_list.append(content)
            # 1. å»æ‰'ç»ƒä¹ ', 'è·‘æ­¥', 'éœ€è¦',==ç»ƒä¹ è·‘æ­¥éœ€è¦
            processed_sentence = ''.join([element for element in content_list if element])
            # 2.å»æ‰  ###ï¼Œ- **ï¼Œ **
            cleaned_text = re.sub(r'### |^- \*\*|\*\*', '', processed_sentence, flags=re.MULTILINE)
            return cleaned_text
        except Exception as e:
            print(f"âš ï¸ APIé”™è¯¯ï¼š{str(e)}")
            # TTSç”Ÿæˆå¤±è´¥ï¼Œç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            time.sleep(0.03)
            client_socket.sendall("END_OF_STREAM\n".encode())

# EdgeTTSæ–‡å­—ç”Ÿæˆè¯­éŸ³
class EdgeTTSTextToSpeech:
    def __init__(self):
        self.voice = "zh-CN-XiaoxiaoNeural"# zh-TW-HsiaoYuNeural
        self.rate = '+16%'
        self.volume = '+0%'
        self.pitch = '+0Hz'

        self.communicate_path = "response.mp3"

    def generate_audio(self, client_socket, text):# EdgeTTSæ–‡å­—ç”Ÿæˆè¯­éŸ³
        try:
            communicate = edge_tts.Communicate(
                text = text,
                voice = self.voice,
                rate = self.rate,
                volume = self.volume,
                pitch = self.pitch)
            communicate.save_sync(self.communicate_path)


            return self.communicate_path# print("è¯­éŸ³æ–‡ä»¶å·²ç”Ÿæˆ...")
        except Exception as e:
            print(f"âš ï¸ TTSç”Ÿæˆå¤±è´¥: {str(e)}")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())

# FFmpeg éŸ³é¢‘è½¬æ¢å™¨
class FFmpegToWav:
    def __init__(self, sample_rate, channels, bit_depth):
        self.sample_rate = sample_rate
        self.channels = channels
        if bit_depth in [16, 24]:
            self.bit_depth = bit_depth
        else:
            raise ValueError("bit_depth å¿…é¡»æ˜¯ 16 æˆ– 24")

    def convert_to_wav(self, client_socket, input_file, output_file):
        codec = 'pcm_s16le' if self.bit_depth == 16 else 'pcm_s24le'
        try:
            subprocess.run([
                    'ffmpeg',
                    '-i', input_file,  # è¾“å…¥æ–‡ä»¶
                    '-vn',  # ç¦ç”¨è§†é¢‘æµ
                    '-acodec', codec,  # åŠ¨æ€è®¾ç½®ç¼–ç å™¨ï¼ˆæ ¹æ®ä½æ·±ï¼‰
                    '-ar', str(self.sample_rate),  # é‡‡æ ·ç‡
                    '-ac', str(self.channels),  # å£°é“æ•°
                    '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                    output_file],
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE)
            print(f"è½¬æ¢æˆåŠŸ: {output_file}")

        except subprocess.CalledProcessError as e:
            print(f"è½¬æ¢å¤±è´¥: {e.stderr.decode('utf-8')}")
        except FileNotFoundError:
            print("é”™è¯¯: æœªæ‰¾åˆ° FFmpegï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…å¹¶æ·»åŠ åˆ°ç³»ç»Ÿ PATH")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())

# MAX98357æ’­æ”¾å£°éŸ³
class MAX98357AudioPlay:
    def __init__(self):
        self.chunk = 1024 # éŸ³é¢‘å¸§æ•°ï¼ˆç¼“å†²åŒºå¤§å°ï¼‰

    def send_wav_file(self, client_socket, wav_file_path):
        with open(wav_file_path, "rb") as audio_file:
            audio_file.seek(44)# è·³è¿‡å‰44å­—èŠ‚çš„WAVæ–‡ä»¶å¤´ä¿¡æ¯
            while True:
                chunk = audio_file.read(1024)
                if not chunk:
                    break
                client_socket.sendall(chunk)
        time.sleep(0.1)
        client_socket.sendall("END_OF_STREAM\n".encode())
        print("å›å¤éŸ³é¢‘å·²å‘é€")

# å°æ™ºAIæœåŠ¡å™¨ ä¸»å¾ªç¯
class XiaoZhi_Ai_TCPServer:
    def __init__(self, host="0.0.0.0", port=8888, save_path="audio/received_audio.wav"):
        self.host = host
        self.port = port
        self.received_audio_filename = save_path
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        #self.fstt = FunasrSpeechToText()# FunASR è¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
        self.fstt = SpeechRecognizer()# BaiduASR è¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
        self.dsr = DeepSeekReply()# deepseek çš„å›å¤
        self.etts = EdgeTTSTextToSpeech()# EdgeTTS æ–‡å­—ç”Ÿæˆè¯­éŸ³
        self.mapl = MAX98357AudioPlay()# MAX98357 æ’­æ”¾éŸ³é¢‘
        self.fftw = FFmpegToWav(sample_rate=8000, channels=1, bit_depth=16)# # FFmpeg éŸ³é¢‘è½¬æ¢å™¨24100, 44100,32000
        self.inmp441tw = INMP441ToWAV()
    def start(self):
        self.socket.bind((self.host, self.port))
        self.socket.listen(1)
        local_ip = socket.gethostbyname(socket.gethostname())
        print("\n=== å°æ™ºAIå¯¹è¯æœºå™¨äººæœåŠ¡å™¨_V1.1 å·²å¯åŠ¨ ===")
        print(f"IPç«¯å£ä¸ºï¼š{local_ip}:{self.port}")
        print("ç­‰å¾…å®¢æˆ·ç«¯çš„è¿æ¥...")
        try:
            while True:  # å¤–å±‚å¾ªç¯æ¥å—æ–°è¿æ¥
                conn, addr = self.socket.accept()
                print(f"æ¥æ”¶åˆ°æ¥è‡ª {addr} çš„æŒä¹…è¿æ¥")
                try:
                    while True:
                        try:
                            # æ¥æ”¶INMP441 éº¦å…‹é£æ•°æ®
                            inmp441wav_path = self.inmp441tw.receive_inmp441_data(conn)

                            # FunASRè¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
                            fstt_text = self.fstt.recognize(conn, inmp441wav_path)
                            print("FunASR è¯­éŸ³è¯†åˆ«---ï¼š", fstt_text)

                            # DeepSeek ç”Ÿæˆå›å¤
                            if fstt_text.strip():
                                gdr_text = self.dsr.get_deepseek_response(conn, fstt_text)
                                print("DeepSeek çš„å›å¤---ï¼š", gdr_text)

                                # EdgeTTS æ–‡å­—ç”Ÿæˆè¯­éŸ³
                                tts_path = self.etts.generate_audio(conn, gdr_text)
                                print("EdgeTTS éŸ³é¢‘åœ°å€---ï¼š", tts_path)
                                # tts_path_file_size = os.path.getsize(tts_path)

                                # FFmpeg éŸ³é¢‘è½¬æ¢å™¨
                                self.fftw.convert_to_wav(conn, tts_path, 'output.wav')

                                # MAX98357 æ’­æ”¾éŸ³é¢‘'audio/textlen44-43380.wav'
                                self.mapl.send_wav_file(conn, 'output.wav')  # gada
                            else:
                                print('FunASRè¯­éŸ³è¯†åˆ«ä¸ºç©ºï¼Œç»§ç»­è®²è¯....')
                                time.sleep(0.03)
                                conn.sendall("END_OF_STREAM\n".encode())



                        except ConnectionError as e:
                            print(f"è¿æ¥å¼‚å¸¸: {e}")
                            break  # é€€å‡ºå†…å±‚å¾ªç¯ï¼Œå…³é—­è¿æ¥
                        except Exception as e:
                            print(f"å¤„ç†é”™è¯¯: {e}")
                            continue  # ç»§ç»­ç­‰å¾…ä¸‹ä¸€ä¸ªè¯·æ±‚
                finally:
                    conn.close()  # ğŸ”´ å…³é”®ä¿®æ”¹ 3: æ‰‹åŠ¨å…³é—­è¿æ¥
                    print(f"è¿æ¥ {addr} å·²å…³é—­")
        except KeyboardInterrupt:
            print("æœåŠ¡å™¨æ­£åœ¨å…³é—­...")
        finally:
            self.socket.close()

if __name__ == "__main__":
    server = XiaoZhi_Ai_TCPServer()
    server.start()
