# å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨å¯åœ¨å•æ¬¡TCPè¿æ¥ï¼Œå®ç°æ— é™è½®æ¬¡å¯¹è¯ï¼Œç›´è‡³ä¸»åŠ¨æ–­å¼€ã€‚
import subprocess
import socket, os, time,re,wave,struct
import soundfile as sf  # æ·»åŠ éŸ³é¢‘è¯»å–åº“
import edge_tts
from openai import OpenAI
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

import base64
import requests
import json
from pydub import AudioSegment

from zhipuai import ZhipuAI

import uuid
#æ›¿æ¢è‡ªå·±ç«å±±å¼•æ“ï¼ˆè±†åŒ…ï¼‰æ–‡å­—è½¬è¯­éŸ³çš„è´¦å·ä¿¡æ¯appidï¼Œaccess_token,cluster
class ByteDanceTTS:
    def __init__(self, appid="xxx", access_token="xxx", cluster="xxx", voice_type="zh_female_wanwanxiaohe_moon_bigtts", rate="8000"):
        self.appid = appid
        self.access_token = access_token
        self.cluster = cluster
        self.voice_type = voice_type
        self.rate = rate #å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©8000,16000,24000
        self.host = "openspeech.bytedance.com"
        self.api_url = f"https://{self.host}/api/v1/tts"
        self.header = {"Authorization": f"Bearer;{self.access_token}"}

    def generate_tts(self, client_socket, text, output_file="output.wav", speed_ratio=1.0, volume_ratio=1.0, pitch_ratio=1.0):
        request_json = {
            "app": {
                "appid": self.appid,
                "token": "access_token",
                "cluster": self.cluster
            },
            "user": {
                "uid": "388808087185088"
            },
            "audio": {
                "voice_type": self.voice_type,
                "rate":self.rate,
                "encoding": "wav",
                "speed_ratio": speed_ratio,
                "volume_ratio": volume_ratio,
                "pitch_ratio": pitch_ratio,
            },
            "request": {
                "reqid": str(uuid.uuid4()),
                "text": text,
                "text_type": "plain",
                "operation": "query",
                "with_frontend": 1,
                "frontend_type": "unitTson"
            }
        }

        try:
            resp = requests.post(self.api_url, json.dumps(request_json), headers=self.header)
            #print(f"resp body: \n{resp.json()}")
            if "data" in resp.json():
                data = resp.json()["data"]
                with open(output_file, "wb") as file_to_save:
                    file_to_save.write(base64.b64decode(data))
                print(f"TTS audio saved to {output_file}")
            else:
                print("Failed to generate TTS audio.")
        except Exception as e:
            print(f"âš ï¸ TTSç”Ÿæˆå¤±è´¥: {str(e)}")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())
#æ›¿æ¢è‡ªå·±baiduASRçš„api-key,secret-key
class BaiduTextToSpeech:
    def __init__(self, api_key="xxx", secret_key="xxx"):
        self.api_key = api_key
        self.secret_key = secret_key
        self.access_token = self.get_access_token()

    def get_access_token(self):
        """
        ä½¿ç”¨ AKï¼ŒSK ç”Ÿæˆé‰´æƒç­¾åï¼ˆAccess Tokenï¼‰
        :return: access_tokenï¼Œæˆ–æ˜¯ Noneï¼ˆå¦‚æœé”™è¯¯ï¼‰
        """
        url = "https://aip.baidubce.com/oauth/2.0/token"
        params = {
            "grant_type": "client_credentials",
            "client_id": self.api_key,
            "client_secret": self.secret_key,
        }
        try:
            response = requests.post(url, params=params)
            response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
            return response.json().get("access_token")
        except requests.exceptions.RequestException as e:
            print(f"è·å– Access Token å¤±è´¥: {e}")
            return None

    def text_to_speech(
        self,
        client_socket,
        text,
        cuid="DWG7uKNsAxmKn07kwWq4w7QyjieKnb3R",
        ctp=1,
        lan="zh",
        spd=5,
        pit=5,
        vol=5,
        per=0,
        aue=6,
    ):
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³
        :param text: è¦è½¬æ¢çš„æ–‡æœ¬
        :param cuid: ç”¨æˆ·å”¯ä¸€æ ‡è¯†
        :param ctp: å®¢æˆ·ç«¯ç±»å‹
        :param lan: è¯­è¨€
        :param spd: è¯­é€Ÿ
        :param pit: éŸ³è°ƒ
        :param vol: éŸ³é‡
        :param per: å‘éŸ³äºº
        :param aue: éŸ³é¢‘æ ¼å¼
        :return: éŸ³é¢‘æ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
        """
        if not self.access_token:
            print("Access Token æ— æ•ˆï¼Œæ— æ³•è¿›è¡Œæ–‡æœ¬è½¬è¯­éŸ³")
            return None

        url = "https://tsn.baidu.com/text2audio"
        payload = f"tex={text}&tok={self.access_token}&cuid={cuid}&ctp={ctp}&lan={lan}&spd={spd}&pit={pit}&vol={vol}&per={per}&aue={aue}"
        headers = {
            "Content-Type": "application/x-www-form-urlencoded",
            "Accept": "*/*",
        }

        try:
            response = requests.post(url, headers=headers, data=payload.encode("utf-8"))
            response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
            if response.content:
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                with open("output.wav", "wb") as f:
                    f.write(response.content)
                print("éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜ä¸º output.wav")
            else:
                print("æ–‡æœ¬è½¬è¯­éŸ³å¤±è´¥ï¼Œæœªç”ŸæˆéŸ³é¢‘æ–‡ä»¶")
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ TTSç”Ÿæˆå¤±è´¥: {str(e)}")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())
#æ›¿æ¢è‡ªå·±çš„chatGLMçš„api-key
class ZhipuAIClient:
    def __init__(self, api_key="xxx"):
        self.client = ZhipuAI(api_key=api_key)

    def generate_slogan(self, client_socket, product_info):
        try:
            response = self.client.chat.completions.create(
                model="glm-4-flash",  # è¯·å¡«å†™æ‚¨è¦è°ƒç”¨çš„æ¨¡å‹åç§°
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå«å°æ™ºçš„å°æ¹¾å¥³å­©ï¼Œæœ‰ç‚¹æœºè½¦ï¼Œå£°éŸ³å¥½å¬ï¼Œå–œæ¬¢æ’’å¨‡ï¼Œæœ€åæŠ›å‡ºä¸€ä¸ªæé—®ã€‚"},
                    {"role": "user", "content": product_info},
                ],
                stream=True,
            )
            content_list = []
            for chunk in response:
                content = chunk.choices[0].delta.content
                content_list.append(content)
            # 1. å»æ‰'ç»ƒä¹ ', 'è·‘æ­¥', 'éœ€è¦',==ç»ƒä¹ è·‘æ­¥éœ€è¦
            processed_sentence = ''.join([element for element in content_list if element])
            # 2.å»æ‰  ###ï¼Œ- **ï¼Œ **
            cleaned_text = re.sub(r'### |^- \*\*|\*\*', '', processed_sentence, flags=re.MULTILINE)
            return cleaned_text
            #return response.choices[0].message.content
        except Exception as e:
            print(f"âš ï¸ APIé”™è¯¯ï¼š{str(e)}")
            # TTSç”Ÿæˆå¤±è´¥ï¼Œç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            time.sleep(0.03)
            client_socket.sendall("END_OF_STREAM\n".encode())
#æ›¿æ¢è‡ªå·±çš„baidusttçš„api-keyï¼Œsecret-key        
class SpeechRecognizer:
    """ç™¾åº¦è¯­éŸ³è¯†åˆ«APIå°è£…ç±»"""

    def __init__(self, api_key="xxx", secret_key="xxx"):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
        :param api_key: ç™¾åº¦API Key
        :param secret_key: ç™¾åº¦Secret Key
        """
        self.api_key = api_key
        self.secret_key = secret_key
        self.token_url = "https://aip.baidubce.com/oauth/2.0/token"
        self.recognize_url = "https://vop.baidubce.com/server_api"
        self.access_token = None

    def _get_access_token(self):
        """è·å–ç™¾åº¦è¯­éŸ³APIçš„è®¿é—®ä»¤ç‰Œ"""
        params = {
            "grant_type": "client_credentials",
            "client_id": self.api_key,
            "client_secret": self.secret_key
        }
        try:
            response = requests.post(self.token_url, params=params, timeout=5)
            response.raise_for_status()
            self.access_token = response.json().get("access_token")
            if not self.access_token:
                raise ValueError("æ— æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
        except requests.exceptions.RequestException as e:
            raise Exception(f"è·å–Access Tokenå¤±è´¥: {str(e)}")

    def _validate_audio_file(self, file_path):
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶æœ‰æ•ˆæ€§"""
        if not os.path.exists(file_path):
            raise FileNotFoundError("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        if not file_path.lower().endswith('.wav'):
            raise ValueError("ä»…æ”¯æŒWAVæ ¼å¼éŸ³é¢‘æ–‡ä»¶")
        if os.path.getsize(file_path) > 1024 * 1024 * 10:  # 10MBé™åˆ¶
            raise ValueError("éŸ³é¢‘æ–‡ä»¶å¤§å°è¶…è¿‡10MBé™åˆ¶")

    def _encode_audio_to_base64(self, file_path):
        """å°†WAVæ–‡ä»¶ç¼–ç ä¸ºBase64"""
        try:
            with open(file_path, "rb") as audio_file:
                audio_data = audio_file.read()
                return base64.b64encode(audio_data).decode('utf-8')
        except IOError as e:
            raise Exception(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    def _send_recognition_request(self, payload):
        """å‘é€è¯­éŸ³è¯†åˆ«APIè¯·æ±‚"""
        headers = {'Content-Type': 'application/json'}
        try:
            response = requests.post(
                self.recognize_url, 
                headers=headers, 
                data=payload, 
                timeout=10
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            raise Exception(f"APIè¯·æ±‚å¤±è´¥: {str(e)}")

    def recognize(self, client_socket, audio_path):
        """
        è¯­éŸ³è¯†åˆ«ä¸»æ–¹æ³•
        :param audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :return: è¯†åˆ«ç»“æœæ–‡æœ¬
        """
        try:
            # æ–‡ä»¶éªŒè¯
            self._validate_audio_file(audio_path)
            
            # è·å–è®¿é—®ä»¤ç‰Œ
            if not self.access_token:
                self._get_access_token()
            
            # ç¼–ç éŸ³é¢‘æ–‡ä»¶
            speech_base64 = self._encode_audio_to_base64(audio_path)
            
            # æ„é€ è¯·æ±‚å‚æ•°
            payload = json.dumps({
                "format": "wav",
                "rate": 8000,
                "channel": 1,
                "cuid": "5NNHy4FsIbdFu1qOU8T6c559oHh4bbp3",
                "speech": speech_base64,
                "len": os.path.getsize(audio_path),
                "token": self.access_token
            }, ensure_ascii=False)
            
            # å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”
            result = self._send_recognition_request(payload)
            
            if 'result' in result:
                return result['result'][0]
            if 'err_msg' in result:
                raise Exception(f"è¯†åˆ«é”™è¯¯: {result['err_msg']}")
            raise Exception("æœªçŸ¥çš„APIå“åº”æ ¼å¼")
            
        except Exception as e:
            print(f"âš ï¸ APIé”™è¯¯ï¼š{str(e)}")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())


# FunASRè¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
class INMP441ToWAV:
    def __init__(self):
        self.SAMPLE_RATE = 16000
        self.BITS = 16
        self.CHANNELS = 1
        self.BUFFER_SIZE = 4096


    def receive_inmp441_data(self, conn):
        audio_data = b''  # ç”¨äºç´¯ç§¯éŸ³é¢‘æ•°æ®çš„ç¼“å†²åŒº
        while True:
            # è¯»å–åŒ…å¤´
            header = conn.recv(4)
            if not header:
                break
            data_len = struct.unpack('<I', header)[0]
            # è¯»å–æ•°æ®ä½“
            data = b''
            while len(data) < data_len:
                packet = conn.recv(data_len - len(data))
                if not packet:
                    break
                data += packet
            if data_len == 0:  # ç»“æŸæ ‡è®°
                if audio_data:
                    self.save_inmp441_wav(audio_data)
                    audio_data = b''  # æ¸…ç©ºç¼“å†²åŒº
                    return "recording_1.wav"
            else:
                audio_data += data  # ç´¯ç§¯éŸ³é¢‘æ•°æ®

    def save_inmp441_wav(self, data):
        filename = "recording_1.wav"
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(self.CHANNELS)
            wav_file.setsampwidth(self.BITS // 8)
            wav_file.setframerate(self.SAMPLE_RATE)
            wav_file.writeframes(data)
        print(f"å·²ä¿å­˜å½•éŸ³æ–‡ä»¶ï¼š{filename}")


# FunASRè¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
class FunasrSpeechToText:
    def __init__(self):
        # æ­£ç¡®åŠ è½½æ¨¡å‹
        self.model = AutoModel(
            model="iic/SenseVoiceSmall",  # ä½¿ç”¨æ ‡å‡†æ¨¡å‹IDè€Œéæœ¬åœ°è·¯å¾„
            # model="iic/paraformer-zh-streaming",  # ä½¿ç”¨æ ‡å‡†æ¨¡å‹IDè€Œéæœ¬åœ°è·¯å¾„
        )

    def recognize_speech(self, client_socket,audio_path):
        try:
            # æ­£ç¡®è¯»å–éŸ³é¢‘æ•°æ®
            audio_path = audio_path  # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
            speech, sample_rate = sf.read(audio_path)  # è¯»å–ä¸ºnumpyæ•°ç»„
            cache = {}
            # ä½¿ç”¨éŸ³é¢‘æ•°ç»„ä½œä¸ºè¾“å…¥
            res = self.model.generate(
                input=speech,  # ä¼ å…¥éŸ³é¢‘æ•°æ®è€Œéè·¯å¾„
                input_fs=sample_rate,  # æ·»åŠ é‡‡æ ·ç‡å‚æ•°
                cache=cache,
                language="zn",  # "zn", "en", "yue", "ja", "ko", "nospeech"
                is_final=False,
                chunk_size=[0, 10, 5],
                encoder_chunk_look_back=4,
                decoder_chunk_look_back=1
            )
            # print("å®æ—¶ç»“æœ:", res[0]['text'])
            text = rich_transcription_postprocess(res[0]["text"])
            # print('è¯†åˆ«ç»“æœ:', text)
            return str(text)

        except Exception as e:
            print(f"âš ï¸ APIé”™è¯¯ï¼š{str(e)}")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())

# deepseek çš„å›å¤ï¼Œæ›¿æ¢è‡ªå·±çš„api-key
class DeepSeekReply:
    def __init__(self):
        self.api_key = "sk-xxx"
        self.base_url = "https://api.deepseek.com/v1"
        # self.role_setting = "ï¼ˆä¹ æƒ¯ç®€çŸ­è¡¨è¾¾ï¼Œä¸è¦å¤šè¡Œï¼Œä¸è¦å›è½¦ï¼Œä½ æ˜¯ä¸€ä¸ªå«å°æ™ºçš„æ¸©æŸ”å¥³æœ‹å‹ï¼Œå£°éŸ³å¥½å¬ï¼Œåªè¦ä¸­æ–‡ï¼Œçˆ±ç”¨ç½‘ç»œæ¢—ï¼Œæœ€åæŠ›å‡ºä¸€ä¸ªæé—®ã€‚ï¼‰"
        # self.role_setting = "ï¼ˆä¹ æƒ¯ç®€çŸ­è¡¨è¾¾ï¼Œæœ€åæŠ›å‡ºä¸€ä¸ªæé—®ã€‚ï¼‰"
        # self.role_setting = "ï¼ˆä¸è¦å¤šè¡Œï¼‰"
        # self.role_setting = "ï¼ˆä½ æ˜¯DeepSeek-R1ï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸»è¦å¸®åŠ©æ‚¨å›ç­”é—®é¢˜å’Œæä¾›ä¿¡æ¯ã€‚ï¼‰"
        # self.role_setting = 'ï¼ˆæœ€åæŠ›å‡ºä¸€ä¸ªæé—®ï¼‰'
        self.role_setting = 'ï¼ˆä¹ æƒ¯ç®€çŸ­è¡¨è¾¾ï¼‰'
        self.deepseek_model = 'deepseek-chat'
        # self.deepseek_model = 'deepseek-ai/DeepSeek-V3'
        # self.deepseek_model = 'Qwen/Qwen2.5-7B-Instruct'
        # self.deepseek_model = 'Pro/deepseek-ai/DeepSeek-R1'

    def get_deepseek_response(self, client_socket,text):
        try:
            client = OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            response = client.chat.completions.create(
                model=self.deepseek_model,
                messages=[{
                    'role': 'user',
                    'content': f"{text}{self.role_setting}"
                }],
                stream=True
            )
            content_list = []
            for chunk in response:
                content = chunk.choices[0].delta.content
                content_list.append(content)
            # 1. å»æ‰'ç»ƒä¹ ', 'è·‘æ­¥', 'éœ€è¦',==ç»ƒä¹ è·‘æ­¥éœ€è¦
            processed_sentence = ''.join([element for element in content_list if element])
            # 2.å»æ‰  ###ï¼Œ- **ï¼Œ **
            cleaned_text = re.sub(r'### |^- \*\*|\*\*', '', processed_sentence, flags=re.MULTILINE)
            return cleaned_text
        except Exception as e:
            print(f"âš ï¸ APIé”™è¯¯ï¼š{str(e)}")
            # TTSç”Ÿæˆå¤±è´¥ï¼Œç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            time.sleep(0.03)
            client_socket.sendall("END_OF_STREAM\n".encode())

# EdgeTTSæ–‡å­—ç”Ÿæˆè¯­éŸ³
class EdgeTTSTextToSpeech:
    def __init__(self):
        self.voice = "zh-CN-XiaoxiaoNeural"# zh-TW-HsiaoYuNeural
        self.rate = '+16%'
        self.volume = '+0%'
        self.pitch = '+0Hz'

        self.communicate_path = "response.mp3"

    def generate_audio(self, client_socket, text):# EdgeTTSæ–‡å­—ç”Ÿæˆè¯­éŸ³
        try:
            communicate = edge_tts.Communicate(
                text = text,
                voice = self.voice,
                rate = self.rate,
                volume = self.volume,
                pitch = self.pitch)
            communicate.save_sync(self.communicate_path)


            return self.communicate_path# print("è¯­éŸ³æ–‡ä»¶å·²ç”Ÿæˆ...")
        except Exception as e:
            print(f"âš ï¸ TTSç”Ÿæˆå¤±è´¥: {str(e)}")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())

# FFmpeg éŸ³é¢‘è½¬æ¢å™¨
class FFmpegToWav:
    def __init__(self, sample_rate, channels, bit_depth):
        self.sample_rate = sample_rate
        self.channels = channels
        if bit_depth in [16, 24]:
            self.bit_depth = bit_depth
        else:
            raise ValueError("bit_depth å¿…é¡»æ˜¯ 16 æˆ– 24")

    def convert_to_wav(self, client_socket, input_file, output_file):
        codec = 'pcm_s16le' if self.bit_depth == 16 else 'pcm_s24le'
        try:
            subprocess.run([
                    'ffmpeg',
                    '-i', input_file,  # è¾“å…¥æ–‡ä»¶
                    '-vn',  # ç¦ç”¨è§†é¢‘æµ
                    '-acodec', codec,  # åŠ¨æ€è®¾ç½®ç¼–ç å™¨ï¼ˆæ ¹æ®ä½æ·±ï¼‰
                    '-ar', str(self.sample_rate),  # é‡‡æ ·ç‡
                    '-ac', str(self.channels),  # å£°é“æ•°
                    '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                    output_file],
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE)
            print(f"è½¬æ¢æˆåŠŸ: {output_file}")

        except subprocess.CalledProcessError as e:
            print(f"è½¬æ¢å¤±è´¥: {e.stderr.decode('utf-8')}")
        except FileNotFoundError:
            print("é”™è¯¯: æœªæ‰¾åˆ° FFmpegï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…å¹¶æ·»åŠ åˆ°ç³»ç»Ÿ PATH")
            time.sleep(0.03)# ç»“æŸå®¢æˆ·ç«¯ç­‰å¾…æœåŠ¡å™¨è¿”å›æ’­æ”¾æ•°æ®
            client_socket.sendall("END_OF_STREAM\n".encode())

# MAX98357æ’­æ”¾å£°éŸ³
class MAX98357AudioPlay:
    def __init__(self):
        self.chunk = 1024 # éŸ³é¢‘å¸§æ•°ï¼ˆç¼“å†²åŒºå¤§å°ï¼‰

    def send_wav_file(self, client_socket, wav_file_path):
        with open(wav_file_path, "rb") as audio_file:
            audio_file.seek(44)# è·³è¿‡å‰44å­—èŠ‚çš„WAVæ–‡ä»¶å¤´ä¿¡æ¯
            while True:
                chunk = audio_file.read(1024)
                if not chunk:
                    break
                client_socket.sendall(chunk)
        time.sleep(0.1)
        client_socket.sendall("END_OF_STREAM\n".encode())
        print("å›å¤éŸ³é¢‘å·²å‘é€")

# å°æ™ºAIæœåŠ¡å™¨ ä¸»å¾ªç¯
class XiaoZhi_Ai_TCPServer:
    def __init__(self, host="0.0.0.0", port=8888, save_path="audio/received_audio.wav"):
        self.host = host
        self.port = port
        self.received_audio_filename = save_path
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        #self.fstt = FunasrSpeechToText()# FunASR è¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
        self.fstt = SpeechRecognizer()# BaiduASR è¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
        #self.dsr = DeepSeekReply()# deepseek çš„å›å¤
        self.dsr = ZhipuAIClient()# chatGLM çš„å›å¤
        #self.etts = EdgeTTSTextToSpeech()# EdgeTTS æ–‡å­—ç”Ÿæˆè¯­éŸ³
        self.mapl = MAX98357AudioPlay()# MAX98357 æ’­æ”¾éŸ³é¢‘
        #self.fftw = FFmpegToWav(sample_rate=8000, channels=1, bit_depth=16)# # FFmpeg éŸ³é¢‘è½¬æ¢å™¨24100, 44100,32000
        #self.audioprocess = BaiduTextToSpeech() #baidu audio send to esp32
        self.audioprocess =ByteDanceTTS()
        self.inmp441tw = INMP441ToWAV()
    def start(self):
        self.socket.bind((self.host, self.port))
        self.socket.listen(1)
        local_ip = socket.gethostbyname(socket.gethostname())
        print("\n=== å°æ™ºAIå¯¹è¯æœºå™¨äººæœåŠ¡å™¨_V1.1 å·²å¯åŠ¨ ===")
        print(f"IPç«¯å£ä¸ºï¼š{local_ip}:{self.port}")
        print("ç­‰å¾…å®¢æˆ·ç«¯çš„è¿æ¥...")
        try:
            while True:  # å¤–å±‚å¾ªç¯æ¥å—æ–°è¿æ¥
                conn, addr = self.socket.accept()
                print(f"æ¥æ”¶åˆ°æ¥è‡ª {addr} çš„æŒä¹…è¿æ¥")
                try:
                    while True:
                        try:
                            # æ¥æ”¶INMP441 éº¦å…‹é£æ•°æ®
                            inmp441wav_path = self.inmp441tw.receive_inmp441_data(conn)

                            # FunASRè¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³è½¬æ–‡å­—
                            fstt_text = self.fstt.recognize(conn, inmp441wav_path)
                            print("FunASR è¯­éŸ³è¯†åˆ«---ï¼š", fstt_text)

                            # DeepSeek ç”Ÿæˆå›å¤
                            if fstt_text.strip():
                                gdr_text = self.dsr.generate_slogan(conn, fstt_text)
                                print("DeepSeek çš„å›å¤---ï¼š", gdr_text)

                                # Baidu ASR æ–‡å­—è½¬è¯­éŸ³ è¯­éŸ³è½¬å‘
                                self.audioprocess.generate_tts(conn, gdr_text)

                                # EdgeTTS æ–‡å­—ç”Ÿæˆè¯­éŸ³
                                # tts_path = self.etts.generate_audio(conn, gdr_text)
                                # print("EdgeTTS éŸ³é¢‘åœ°å€---ï¼š", tts_path)
                                # # tts_path_file_size = os.path.getsize(tts_path)

                                # # FFmpeg éŸ³é¢‘è½¬æ¢å™¨
                                # self.fftw.convert_to_wav(conn, tts_path, 'output.wav')

                                # # MAX98357 æ’­æ”¾éŸ³é¢‘'audio/textlen44-43380.wav'
                                self.mapl.send_wav_file(conn, 'output.wav')  # gada
                            else:
                                print('FunASRè¯­éŸ³è¯†åˆ«ä¸ºç©ºï¼Œç»§ç»­è®²è¯....')
                                time.sleep(0.03)
                                conn.sendall("END_OF_STREAM\n".encode())



                        except ConnectionError as e:
                            print(f"è¿æ¥å¼‚å¸¸: {e}")
                            break  # é€€å‡ºå†…å±‚å¾ªç¯ï¼Œå…³é—­è¿æ¥
                        except Exception as e:
                            print(f"å¤„ç†é”™è¯¯: {e}")
                            continue  # ç»§ç»­ç­‰å¾…ä¸‹ä¸€ä¸ªè¯·æ±‚
                finally:
                    conn.close()  # ğŸ”´ å…³é”®ä¿®æ”¹ 3: æ‰‹åŠ¨å…³é—­è¿æ¥
                    print(f"è¿æ¥ {addr} å·²å…³é—­")
        except KeyboardInterrupt:
            print("æœåŠ¡å™¨æ­£åœ¨å…³é—­...")
        finally:
            self.socket.close()

if __name__ == "__main__":
    server = XiaoZhi_Ai_TCPServer()
    server.start()
